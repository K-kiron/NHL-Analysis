---
layout: post
title: Milestone 2
---

# <strong>DATA PATH RULES</strong>
## To run the code correctly, please follow the instructions below:<br> 
Rename the data folder to 'IFT6758_Data' and place the folder under the main(father) path <br>
![path_img](../images/path1_m2.png)<br>![path_img](../images/path2_m2.png)<br>

## <strong>1. Experiment Tracking</strong>

### See the following parts.

## <strong>2. Feature Engineering I</strong>

### In this milestone, we split the raw data into train, validation and test sets:

![data_split](../images/data_split_m2.png)

### <strong>Question 1</strong>: 

Here we have calculated shot_distance and shot_angle and added them as new columns to the dataframe. And set the number of bins to 20 for plot.<br>
As we can see from the chart, although the number of no-goals is significantly higher than the number of goals, the two roughly follow an approximate distribution.

![fe_q1_1](../images/m2_fe1_q1_1.png)

From the graph we can see that shot counts are high at [0,50] but decrease when the distance increases. This is very understandable, because the closer the distance, the easier it is to goal. But the shot counts are also lower at [0,10], due to the fact that it's too close to the goalpost, and has probably been intercepted by an opposing player before that.

![fe_q1_2](../images/m2_fe1_q1_2.png)

From the image we can see that shot counts show a decreasing trend with increasing angle. This indicates that most of the athletes tend to shoot from the front rather than from a more oblique angle. This is also in line with our common sense: more oblique angles tend to be harder to get a goal.

![fe_q1_3](../images/m2_fe1_q1_3.png)

From the image we can see that the shot counts have a significant density when the distance is close and the angle is close to 0. This is also in line with common sense: shots tend to be concentrated closer to the front of the net.

### <strong>Question 2</strong>:

In this question instead of histograms, we chose bar charts for plotting. Because for continuous data, the probability of goal at each distance point (or angle point) will only be 1 or 0, the data we get in this case is not meaningful for any study. So we divided the distances and angles into 20 intervals and calculated the goal rate for each interval separately. The results are as follows:

![fe_q2_1](../images/m2_fe1_q2_1.png)

We can see from the graph that the distribution is roughly "U" shaped with a low centre and high ends. The higher goal rate from close range is well understood, whereas the lower goal rate from mid-range may be due to a large number of players congregating in the centre of the pitch, which makes scoring goals less easy. The high rate of goals from further distances may be due to quick counter-attacks where the opposing players have no time to react.

![fe_q2_2](../images/m2_fe1_q2_2.png)

From the image we can see that the goal rate is higher when the angle is close to 0, while the other angles have roughly the same goal rate. This is also aligned with our common sense: shots from the front are more likely to goal.

### <strong>Question 3</strong>:

![fe_q3](../images/m2_fe1_q3.png)

From the image we can see that the empty net stays at a very low level no matter what the shot distance is. This shows that in most cases the goalkeepers of both teams stay in front of their own net.<br>
According to our domain knowledge, "it is very rare to score a non-open goal to an opposing team in their own defensive zone". However, we can see from the picture that there are some non-empty long range goals in the [150,175] zone, which contradicts our domain knowledge and suggests that there may be anomalous data.


## <strong>3. Baseline Models</strong>

### <strong>Question 1</strong>:
<br>
The accuracy score of our model on the validation set is approximately 0.906, which means that it correctly predicted about 90.6% of the samples in the validation set.Accuracy is a useful metric when the classes are balanced, but it can be misleading when the class distribution is inbalance.I calculate it by comparing the model's predictions against the actual outcomes in the validation set. It's the number of correct predictions divided by the total number of predictions. 
in summary even  though the accuracy is high in the model but the classifier doesnt work well as our classes are inbalance. this might be due to the feutures that we chosed. goals are not correlated with the distance of the shot from net.<br>

### <strong>Question 2</strong>: 
![q2_2](../images/Q2_1.png)<br>
The first plot labeled "ROC curve for distance"shows the performance of my classifier in terms of the trade-off between the true positive rate and false positive rate. The area under the curve (AUC) is 0.53, which is slightly better than random guessing (AUC of 0.5). However, an AUC this close to 0.5 indicates that the model does not have a strong discriminatory ability.<br>
![q2_1](../images/Q2_2.png)<br>
The goal rate (#goals / (#no_goals + #goals)) as a function of the shot probability model percentile, i.e. if a value is the 70th percentile, it is above 70% of the data. <br>
![q2_3](../images/Q2_3.png)<br>
third plot is cumulative percentage of goals, which is an empirical cumulative distribution function (ECDF) of the predicted probabilities for the goals. This can help understand the concentration of goals within certain predicted probability ranges.<br>
![q2_4](../images/Q2_4.png)<br>
 is a calibration curve, it show how well the predicted probabilities of the goals are calibrated. The ideal calibration curve would be a straight line at a 45-degree angle. Deviations from this line indicate over- or under-confidence in predictions. if the model is perfectly calibrated, the predicted probabilities of the positive class would match the actual frequency of the positive class.
### <strong>Question 3</strong>:
![q3_1](../images/3a_ROC_curves.png)<br>
models trained using distance from net (distance from net alone or both distance and angle) performed better than those trained using angle from net alone. Models trained on distance tend more towards the top left corner on the ROC plot than do models using angle only, and they have an AUC of 0.65 compared to an AUC of 0.51 for angle. Combining distance and angle adds no increased AUC or curve, suggesting that distance is the defining feature. Indeed, the model using angle only has an AUC matching that of the random baseline. The fact that the ROC curves for angle and random baseline are different despite them having the same AUC values highlights the need to look at data in different ways - in this case, it suggests that the model trained on angle is not simply choosing at random.<br>
![q3_2](../images/3b_goal_rates.png)<br>
This plot shows the goal rates at different shot probability model percentiles. Plotting goal rate as a function of shot probability model percentile gives an indication of whether the model favours shots of a certain probability and hints at what the model thinks is a high-quality shot. The random baseline (Figure 3.3.2), as a straight horizonal line at 10% on the goal rate, gives equal weight to goals of all probabilities. The logistic regression model trained on angle gives a higher goal rate to shots around the 50th model percentile and underweights (assigns a lower goal rate to) shots with high or low model percentiles. Similar to the ROC curves, we see that models using distance from net alone and distance + angle have near-identical curves. Both of these models assign a higher-than-baseline goal rate to shots in the upper model percentile (~ > 70 %) and lower-than-baseline to shots in the lower model percentile (except for shots < 5 %), suggesting that they attribute a higher quality to shots in the upper model percentile.
<br>
![q3_3](../images/3c_goal_proportions.png)<br>
The cumulative percentage of goals plot shows how well the models rank the shots by their probability of being a goal. Ideally, a higher proportion of actual goals would be found at higher predicted probabilities.
The model using both features again seems to perform better than the others, as it ranks more goals at higher probability percentiles, but the improvement over the single-feature models is not dramatic.<br>
![q3_4](../images/3d_calibration_plots.png)<br>
A well-calibrated model should have points that lie close to the "perfectly calibrated" line, where the predicted probabilities match the observed frequencies.
The calibration plot shows that Distance, Angle and Distance-angle are calibrated while the random baseline is poorly calibrated, with most predictions clustered at the low probability end and not aligning with the diagonal line representing perfect calibration.distance-angle is passing the perfect line to the point that we can consider over fitting.but we can assume that feature selectioon play a important role in model calibration.
To improve the model, it may be necessary to explore more complex models, additional features, or different data preprocessing techniques.
### <strong>Question 4</strong>:
<br>distance: https://www.comet.com/api/registry/model/item/download?modelItemId=NNWWTsrccam0dBkAcTD6tY43f<br>
<br>angle: https://www.comet.com/api/registry/model/item/download?modelItemId=mtVkSF73afL3TmKZM9VDKXqbP<br>
<br>distance-angle: https://www.comet.com/api/registry/model/item/download?modelItemId=RmkwRg4fFcR9QHAXOde2xh3G6<br>
## <strong>4. Feature Engineering II</strong>

The following are feature names outputted by `feature_eng2_cleaned` (i.e., our feature engineering function provided in `Milestone2/features/feature_eng2.py`) with their respective descriptions:

 <strong>gameSeconds (`int`):</strong> value of number of seconds into the game  <br>
 <strong>period (`int`):</strong> value of the period number (ex: `period = 3` for P-3) <br>
 <strong>x_coordinate(`float`):</strong> x coordinate of the event in feet <br>
 <strong>y_coordinate (`float`):</strong> y coordinate of the event in feet  <br>
 <strong>shotDistance (`float`):</strong> distance between the event and the net  <br>
 <strong>shotAngle (`float`):</strong> acute angle (in degrees) between the event and the goal with respect to the x-axis  <br>
 <strong>shotType (`str`):</strong> type of shot (ex: Wrist Shot, Slap Shot)  <br>
 <strong>LastEventType (`str`):</strong> previous event type (ex: Shot, Goal)  <br>
 <strong>Last_x_coordinate (`float`):</strong> x coordinate of the previous event in feet <br>
 <strong>Last_y_coordinate (`float`):</strong> y coordinate of the previous event in feet <br>
 <strong>timeFromLastEvent (`float`):</strong> time interval in seconds between the current and previous event  <br>
 <strong>DistanceLastEvent (`float`):</strong> distance in feet between the current and previous event  <br>
 <strong>Rebound (`bool`):</strong> boolean value for if the shot was a rebound (`True/1`) or not (`False/0`) <br>
 <strong>changeShotAngle (`bool`):</strong> if `Rebound = True/1`, change in the angle of the puck before and after the rebound  <br>
 <strong>speed (`float`):</strong> speed between current and previous event corresponding to DistanceLastEvent/timeFromLastEvent in ft/s <br>
 <strong>time_since_pp (`float`):</strong> BONUS feature corresponding to the time in seconds since the currently active power-play started <br>
<strong>no_players_home (`int`):</strong> BONUS feature corresponding to the number of home team non-goalie players current on the ice <br>
 <strong>no_players_away (`int`):</strong> BONUS feature corresponding to the number of away team non-goalie players current on the ice <br>
 <strong>is_goal (`bool`):</strong> boolean value where 0 corresponds to a shot (<strong>not</strong> goal), while 1 corresponds to a goal.<br>
 The following features were added by personal initiative:<br>
 <strong>home_pts (`int`):</strong> current number of points scored by the home team during the game (i.e., home score) <br>
 <strong>away_pts (`int`):</strong> current number of points scored by the away team during the game (i.e., away score) <br>
 <strong>diff_pts (`int`):</strong> difference between the current number of points scored by the home and away teams <br>

## <strong>4. Feature Engineering II(bonus)</strong>

We've computed the time (s) since the power-play (PP) started for all penalties (both teams included), for home team penalties, and for away team penalties as a function of period time (in seconds). See the following plots below for the game ID 2016020031 of regular season in 2016 during period 3. Naturally, the y-value (time since PP start) increases as the periodTime increases. Also, the combination of the time since PP start for home team penalties and away team penalties also corresponds to the plot for the time since PP started for all penalties (both teams included). 

![t](../images/timer.png)
![th](../images/timer_home.png)
![ta](../images/timer_away.png)

Moreover, we've determined the number of friendly non-goalie (home team) skaters on the ice as well as the number of opposing non-goalie skaters (away team) on the ice as a function of period time (s). The function generating the data plotted takes as input the game data `pd.Dataframe` as well as the period number `select_period`. See the following plots below for the game ID 2016020031 of regular season in 2016 during period 3:

![hp](../images/homeplayers.png)
![ap](../images/awayplayers.png)

## <strong>5. Advanced Models</strong>

### <strong>Question 1</strong>:

### <strong>Question 2</strong>:

### <strong>Question 3</strong>:


## <strong>6. Give it your best shot!</strong>

<strong>Question 1</strong>: We trained ADABoost with 1 estimator preceded by a Random Forest Classifier for feature selection. After feature selection,  we employed weight sampling to account for the heavily imbalanced dataset (the goal/shot ratio was 10%/90%, which is heavily imbalanced). We trained this model with a `max_depth` of 1,3, and 10, where an inrease in `max_depth` was associated with an increase in all performance metrics.  

### <strong>Question 2</strong>:


## <strong>7. Evaluate on test set</strong>

### <strong>Question 1</strong>:
### <strong>Question 2</strong>:
